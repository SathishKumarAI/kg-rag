{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pdfplumber in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.11.8)\n",
            "Requirement already satisfied: tiktoken in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.12.0)\n",
            "Requirement already satisfied: neo4j in /usr/local/python/3.12.1/lib/python3.12/site-packages (6.0.3)\n",
            "Requirement already satisfied: openai in /usr/local/python/3.12.1/lib/python3.12/site-packages (2.8.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/python/3.12.1/lib/python3.12/site-packages (5.1.2)\n",
            "Requirement already satisfied: transformers in /usr/local/python/3.12.1/lib/python3.12/site-packages (4.57.3)\n",
            "Requirement already satisfied: pdfminer.six==20251107 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pdfplumber) (20251107)\n",
            "Requirement already satisfied: Pillow>=9.1 in /home/codespace/.local/lib/python3.12/site-packages (from pdfplumber) (12.0.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pdfplumber) (5.1.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from pdfminer.six==20251107->pdfplumber) (3.4.4)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pdfminer.six==20251107->pdfplumber) (46.0.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tiktoken) (2025.11.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /home/codespace/.local/lib/python3.12/site-packages (from tiktoken) (2.32.5)\n",
            "Requirement already satisfied: pytz in /home/codespace/.local/lib/python3.12/site-packages (from neo4j) (2025.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /home/codespace/.local/lib/python3.12/site-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (2.12.5)\n",
            "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.12/site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/codespace/.local/lib/python3.12/site-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /home/codespace/.local/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /home/codespace/.local/lib/python3.12/site-packages (from sentence-transformers) (2.9.0+cpu)\n",
            "Requirement already satisfied: scikit-learn in /home/codespace/.local/lib/python3.12/site-packages (from sentence-transformers) (1.7.2)\n",
            "Requirement already satisfied: scipy in /home/codespace/.local/lib/python3.12/site-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (2.3.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.9.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: cffi>=2.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /home/codespace/.local/lib/python3.12/site-packages (from cffi>=2.0.0->cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (2.23)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
            "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pdfplumber tiktoken neo4j openai  sentence-transformers transformers \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0IM-IK0hTyIJ"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import os\n",
        "\n",
        "remote_pdf_url = \"https://arxiv.org/pdf/1709.00666.pdf\"\n",
        "pdf_filename = \"ch02-downloaded.pdf\"\n",
        "\n",
        "response = requests.get(remote_pdf_url)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    with open(pdf_filename, \"wb\") as pdf_file:\n",
        "        pdf_file.write(response.content)\n",
        "else:\n",
        "    print(\"Failed to download the PDF. Status code:\", response.status_code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "d85TG9m9TyIK",
        "outputId": "255184bc-2b5a-4796-f3d1-5ead3bd21b78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Einstein’s Patents a\n"
          ]
        }
      ],
      "source": [
        "import pdfplumber\n",
        "\n",
        "text = \"\"\n",
        "\n",
        "with pdfplumber.open(pdf_filename) as pdf:\n",
        "    for page in pdf.pages:\n",
        "        text += page.extract_text()\n",
        "\n",
        "print(text[0:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.2.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install python-dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from neo4j import GraphDatabase\n",
        "\n",
        "# uri = \"neo4j+s://5db7d1f6.databases.neo4j.io\"  # from Aura\n",
        "# user = \"neo4j\"                                 # or your Aura user\n",
        "# password = \"\"           # reset from Aura console\n",
        "\n",
        "# driver = GraphDatabase.driver(\n",
        "#     uri,\n",
        "#     auth=(user, password),\n",
        "#     notifications_min_severity=\"OFF\",\n",
        "# )\n",
        "\n",
        "# with driver.session() as session:\n",
        "#     res = session.run(\"RETURN 1 AS ok\").single()\n",
        "#     print(\"Neo4j connected:\", res[\"ok\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "6rV2w0t1TyIK",
        "outputId": "a2b13ca3-971a-4c15-f790-2113d0cc5952"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "89\n",
            "Einstein’s Patents and Inventions\n",
            "Asis Kumar Chaudhuri\n",
            "Variable Energy Cyclotron Centre\n",
            "1‐AF Bidhan Nagar, Kolkata‐700 064\n",
            "Abstract: Times magazine selected Albert Einstein, the German born Jewish Scientist as the person of the 20th\n",
            "century. Undoubtedly, 20th century was the age of science and Einstein’s contributions in unravelling mysteries\n",
            "of nature was unparalleled. However, few are aware that Einstein was also a great inventor. He and his\n",
            "collaborators had patented a wide variety of inventions\n"
          ]
        }
      ],
      "source": [
        "from utils import chunk_text\n",
        "\n",
        "chunks = chunk_text(text, 500, 40)\n",
        "print(len(chunks))\n",
        "print(chunks[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "EtlNb7-VTyIL"
      },
      "outputs": [],
      "source": [
        "# %load_ext dotenv\n",
        "# %dotenv\n",
        "\n",
        "# import os\n",
        "# from openai import OpenAI\n",
        "\n",
        "\n",
        "# open_ai_client = OpenAI(\n",
        "#     api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "1vWdE8zLTyIL",
        "outputId": "831bd985-04a5-423b-96bb-582ea3d29619"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Load a local embedding model (no API needed)\n",
        "local_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "def embed(texts):\n",
        "    \"\"\"\n",
        "    Work exactly like your OpenAI embed() function,\n",
        "    but using a free, local embedding model.\n",
        "    \"\"\"\n",
        "    return local_model.encode(texts).tolist()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.04776293784379959, 0.06253523379564285, -0.04059494659304619]\n",
            "89\n",
            "384\n"
          ]
        }
      ],
      "source": [
        "embeddings = embed(chunks)\n",
        "\n",
        "print(embeddings[0][0:3])          # preview numbers\n",
        "print(len(embeddings))             # number of chunks\n",
        "print(len(embeddings[0]))          # should print 384\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Su_E7RDHTyIL"
      },
      "outputs": [],
      "source": [
        "from neo4j import GraphDatabase\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()  # Ensure .env is loaded\n",
        "\n",
        "NEO4J_URI = os.getenv(\"NEO4J_URI\")\n",
        "NEO4J_USERNAME = os.getenv(\"NEO4J_USERNAME\")\n",
        "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
        "\n",
        "driver = GraphDatabase.driver(\n",
        "    NEO4J_URI,\n",
        "    auth=(NEO4J_USERNAME, NEO4J_PASSWORD),\n",
        "    notifications_min_severity=\"OFF\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "nOmrBgVyTyIL"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "EagerResult(records=[], summary=<neo4j._work.summary.ResultSummary object at 0x733eeae1f4a0>, keys=[])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "driver.execute_query(\"\"\"CREATE VECTOR INDEX pdf IF NOT EXISTS\n",
        "FOR (c:Chunk)\n",
        "ON c.embedding\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "lCUqAGEETyIL",
        "outputId": "90064b28-b95e-4b05-8c6f-ba1606de1d8f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "EagerResult(records=[], summary=<neo4j._work.summary.ResultSummary object at 0x733eeb0b4590>, keys=[])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Add to neo4j\n",
        "cypher_query = '''\n",
        "WITH $chunks as chunks, range(0, size($chunks)) AS index\n",
        "UNWIND index AS i\n",
        "WITH i, chunks[i] AS chunk, $embeddings[i] AS embedding\n",
        "MERGE (c:Chunk {index: i})\n",
        "SET c.text = chunk, c.embedding = embedding\n",
        "'''\n",
        "\n",
        "driver.execute_query(cypher_query, chunks=chunks, embeddings=embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "AqQ8FZ1-TyIL",
        "outputId": "6f839824-2605-439b-9a74-492af526c49a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Einstein’s Patents and Inventi\n",
            "[-0.04776293784379959, 0.06253523379564285, -0.04059494659304619]\n"
          ]
        }
      ],
      "source": [
        "records, _, _ = driver.execute_query(\"MATCH (c:Chunk) WHERE c.index = 0 RETURN c.embedding, c.text\")\n",
        "\n",
        "print(records[0][\"c.text\"][0:30])\n",
        "print(records[0][\"c.embedding\"][0:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "6Z-UKsBoTyIL",
        "outputId": "08a29cd2-d1d9-4d73-96cf-bced9051cac8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Albert Einstein topped the list.\n",
            "Einstein’s choice as the person of the century didn’t invoke any resentment, it was generally agreed\n",
            "that 20th century is the age of Science and undoubtedly, Einstein’s contribution to Science, to the\n",
            "understanding of the intricate laws of nature was unparalleled. He greatly influenced modern science;\n",
            "altered our views on space‐time, matter and energy, gave new interpretation to gravity etc. The\n",
            "enormous popularity he enjoyed during his lifetime and even now, is rare for any individual; religious\n",
            "leader, politician,\n",
            "0.8008778095245361 2\n",
            "======\n",
            "Einstein’s life was rather featureless. He diligently worked at the patent office,\n",
            "played violin, discussed physics with his friends, write few not so interesting papers. Then in 1905, he\n",
            "took the academic world by surprise. In the annals of physics, the year 1905 is known as “annus\n",
            "mirabilis” or the year of miracle. Indeed, a miracle happened. Albert Einstein, barely 26 years old,\n",
            "sitting in an obscure Swiss patent office, wrote four papers, each of which produced some sort of\n",
            "revolution in Physics. The papers were published in a single\n",
            "0.800201416015625 20\n",
            "======\n",
            "in nuances of machines and instruments. However, it must also be\n",
            "emphasized that his main occupation was theoretical physics. The inventions he worked upon were\n",
            "his diversions. In his unproductive times he used to work upon on solving mathematical problems (not\n",
            "related to his ongoing theoretical investigations) or took upon some practical problem. As shown in\n",
            "Table. 2, Einstein was involved in three major inventions; (i) refrigeration system with Leo Szilard, (ii)\n",
            "Sound reproduction system with Rudolf Goldschmidt and (iii) automatic camera\n",
            "0.7987239360809326 44\n",
            "======\n",
            "to the four papers mentioned above, in 1905, Einstein, under the supervision of\n",
            "Alfred Kleiner, also submitted his thesis for PhD degree; “A new determination of molecular\n",
            "dimensions.” The thesis was 24 page only. Einstein recounted that his supervisor, Kleiner returned the\n",
            "thesis saying it was too short. Einstein added a single sentence and it was accepted without further\n",
            "comments.\n",
            "The full import of Einstein’s theory took time to percolate even in the academic world. Only\n",
            "few realized their true values, among them was Wilhelm Wein7,\n",
            "0.797755241394043 26\n",
            "======\n"
          ]
        }
      ],
      "source": [
        "question = \"At what time was Einstein really interested in experimental works?\"\n",
        "question_embedding = embed([question])[0]\n",
        "\n",
        "query = '''\n",
        "CALL db.index.vector.queryNodes('pdf', $k, $question_embedding) YIELD node AS hits, score\n",
        "RETURN hits.text AS text, score, hits.index AS index\n",
        "'''\n",
        "similar_records, _, _ = driver.execute_query(query, question_embedding=question_embedding, k=4)\n",
        "\n",
        "for record in similar_records:\n",
        "    print(record[\"text\"])\n",
        "    print(record[\"score\"], record[\"index\"])\n",
        "    print(\"======\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "5X2TVJ8ITyIL",
        "outputId": "e8302af2-7074-4f06-f6a4-e66e40afcc71"
      },
      "outputs": [],
      "source": [
        "# system_message = \"You're en Einstein expert, but can only use the provided documents to respond to the questions.\"\n",
        "# user_message = f\"\"\"\n",
        "# Use the following documents to answer the question that will follow:\n",
        "# {[doc[\"text\"] for doc in similar_records]}\n",
        "\n",
        "# ---\n",
        "\n",
        "# The question to answer using information only from the above documents: {question}\n",
        "# \"\"\"\n",
        "\n",
        "# print(\"Question:\", question)\n",
        "\n",
        "# stream = open_ai_client.chat.completions.create(\n",
        "#     model=\"gpt-4\",\n",
        "#     messages=[\n",
        "#         {\"role\": \"system\", \"content\": system_message},\n",
        "#         {\"role\": \"user\", \"content\": user_message}\n",
        "#     ],\n",
        "#     stream=True,\n",
        "# )\n",
        "# for chunk in stream:\n",
        "#     print(chunk.choices[0].delta.content or \"\", end=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/python/3.12.1/lib/python3.12/site-packages (4.57.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.12.0)\n",
            "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (2.3.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (2.32.5)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: psutil in /home/codespace/.local/lib/python3.12/site-packages (from accelerate) (7.1.3)\n",
            "Requirement already satisfied: torch>=2.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from accelerate) (2.9.0+cpu)\n",
            "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (2025.10.5)\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "!pip install transformers accelerate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Fetching 2 files: 100%|██████████| 2/2 [02:01<00:00, 60.68s/it] \n",
            "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, dtype=torch.float16)\n",
        "\n",
        "def hf_chat(prompt: str):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    outputs = model.generate(**inputs, max_new_tokens=500)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHELU3bFTyIM"
      },
      "outputs": [],
      "source": [
        "try :\n",
        "    driver.execute_query(f\"CREATE FULLTEXT INDEX ftPdfChunk FOR (c:Chunk) ON EACH [c.text]\")\n",
        "except:\n",
        "    print(\"Fulltext Index already exists\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCez2NfJTyIM",
        "outputId": "73026167-e7f2-432e-b0c7-48c9fe2ee9ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CH‐Switzerland\n",
            "Considering Einstein’s upbringing, his interest in inventions and patents was not unusual.\n",
            "Being a manufacturer’s son, Einstein grew upon in an environment of machines and instruments.\n",
            "When his father’s company obtained the contract to illuminate Munich city during beer festival, he\n",
            "was actively engaged in execution of the contract. In his ETH days Einstein was genuinely interested\n",
            "in experimental works. He wrote to his friend, “most of the time I worked in the physical laboratory,\n",
            "fascinated by the direct contact with observation.” Einstein's\n",
            "1.0 42\n",
            "======\n",
            "Einstein\n",
            "left his job at the Patent office and joined the University of Zurich on October 15, 1909. Thereafter, he\n",
            "continued to rise in ladder. In 1911, he moved to Prague University as a full professor, a year later, he\n",
            "was appointed as full professor at ETH, Zurich, his alma‐mater. In 1914, he was appointed Director of\n",
            "the Kaiser Wilhelm Institute for Physics (1914–1932) and a professor at the Humboldt University of\n",
            "Berlin, with a special clause in his contract that freed him from teaching obligations. In the meantime,\n",
            "he was working for\n",
            "0.9835733295862473 31\n",
            "======\n",
            "Einstein’s life was rather featureless. He diligently worked at the patent office,\n",
            "played violin, discussed physics with his friends, write few not so interesting papers. Then in 1905, he\n",
            "took the academic world by surprise. In the annals of physics, the year 1905 is known as “annus\n",
            "mirabilis” or the year of miracle. Indeed, a miracle happened. Albert Einstein, barely 26 years old,\n",
            "sitting in an obscure Swiss patent office, wrote four papers, each of which produced some sort of\n",
            "revolution in Physics. The papers were published in a single\n",
            "0.9707015894298074 20\n",
            "======\n",
            "in nuances of machines and instruments. However, it must also be\n",
            "emphasized that his main occupation was theoretical physics. The inventions he worked upon were\n",
            "his diversions. In his unproductive times he used to work upon on solving mathematical problems (not\n",
            "related to his ongoing theoretical investigations) or took upon some practical problem. As shown in\n",
            "Table. 2, Einstein was involved in three major inventions; (i) refrigeration system with Leo Szilard, (ii)\n",
            "Sound reproduction system with Rudolf Goldschmidt and (iii) automatic camera\n",
            "0.9705479922198971 44\n",
            "======\n"
          ]
        }
      ],
      "source": [
        "hybrid_query = '''\n",
        "CALL {\n",
        "    // vector index\n",
        "    CALL db.index.vector.queryNodes('pdf', $k, $question_embedding) YIELD node, score\n",
        "    WITH collect({node:node, score:score}) AS nodes, max(score) AS max\n",
        "    UNWIND nodes AS n\n",
        "    // We use 0 as min\n",
        "    RETURN n.node AS node, (n.score / max) AS score\n",
        "    UNION\n",
        "    // keyword index\n",
        "    CALL db.index.fulltext.queryNodes('ftPdfChunk', $question, {limit: $k})\n",
        "    YIELD node, score\n",
        "    WITH collect({node:node, score:score}) AS nodes, max(score) AS max\n",
        "    UNWIND nodes AS n\n",
        "    // We use 0 as min\n",
        "    RETURN n.node AS node, (n.score / max) AS score\n",
        "}\n",
        "// dedup\n",
        "WITH node, max(score) AS score ORDER BY score DESC LIMIT $k\n",
        "RETURN node, score\n",
        "'''\n",
        "similar_hybrid_records, _, _ = driver.execute_query(hybrid_query, question_embedding=question_embedding, question=question, k=4)\n",
        "\n",
        "for record in similar_hybrid_records:\n",
        "    print(record[\"node\"][\"text\"])\n",
        "    print(record[\"score\"], record[\"node\"][\"index\"])\n",
        "    print(\"======\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Quo2Hv5ETyIM",
        "outputId": "93c33c50-e951-41e5-f93d-38780ae3061a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: At what time was Einstein really interested in experimental works?\n",
            "Einstein was genuinely interested in experimental works during his days at ETH, as indicated in the provided documents."
          ]
        }
      ],
      "source": [
        "# user_message = f\"\"\"\n",
        "# Use the following documents to answer the question that will follow:\n",
        "# {[doc[\"node\"][\"text\"] for doc in similar_hybrid_records]}\n",
        "\n",
        "# ---\n",
        "\n",
        "# The question to answer using information only from the above documents: {question}\n",
        "# \"\"\"\n",
        "\n",
        "# print(\"Question:\", question)\n",
        "\n",
        "# stream = open_ai_client.chat.completions.create(\n",
        "#     model=\"gpt-4\",\n",
        "#     messages=[\n",
        "#         {\"role\": \"system\", \"content\": system_message},\n",
        "#         {\"role\": \"user\", \"content\": user_message}\n",
        "#     ],\n",
        "#     stream=True,\n",
        "# )\n",
        "# for chunk in stream:\n",
        "#     print(chunk.choices[0].delta.content or \"\", end=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils import chat  # or whatever file you put chat() in\n",
        "\n",
        "user_message = f\"\"\"\n",
        "Use the following documents to answer the question that will follow:\n",
        "{[doc[\"node\"][\"text\"] for doc in similar_hybrid_records]}\n",
        "\n",
        "---\n",
        "\n",
        "The question to answer using information only from the above documents: {question}\n",
        "\"\"\"\n",
        "\n",
        "print(\"Question:\", question)\n",
        "\n",
        "answer = chat(\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\",  \"content\": user_message},\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(answer)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
